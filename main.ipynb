{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f3c2e68d8cd2c13"
  },
  {
   "cell_type": "code",
   "source": [
    "import cudf\n",
    "import cudf as pd\n",
    "import numpy as np\n",
    "import pandas\n",
    "import shap\n",
    "import seaborn as sns\n",
    "import numpy\n",
    "import cupy\n",
    "import tensorflow\n",
    "import os\n",
    "import random\n",
    "\n",
    "from cuml import train_test_split\n",
    "from cuml import SVR\n",
    "from cuml import RandomForestRegressor as CuRF\n",
    "from cuml.metrics import mean_squared_error\n",
    "from keras import Sequential\n",
    "from keras.src.layers import Input, LSTM, Dense\n",
    "from pyswarms.single import GlobalBestPSO\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "SEED = 100\n",
    "\n",
    "\n",
    "def reset_seed(rnd_seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    random.seed(rnd_seed)\n",
    "    numpy.random.seed(rnd_seed)\n",
    "    cupy.random.seed(rnd_seed)\n",
    "    tensorflow.random.set_seed(rnd_seed)\n",
    "\n",
    "\n",
    "cluster = LocalCUDACluster()\n",
    "client = Client(cluster)\n",
    "reset_seed()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6e345ae81073f29",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d53fe60dddad7a9"
  },
  {
   "cell_type": "code",
   "source": [
    "df_water = pd.read_csv('./dataset/water.csv', sep=\";\", decimal=\".\", header=0)\n",
    "df_electricity = pd.read_csv('./dataset/electricity.csv', sep=\";\", decimal=\".\", header=0)\n",
    "df_climatic = pd.read_csv('./dataset/climatic.csv', sep=\";\", decimal=\".\", header=0)\n",
    "\n",
    "df_water[\"data\"] = pd.to_datetime(df_water[\"data\"], format=\"%d/%m/%Y\")\n",
    "df_electricity[\"data\"] = pd.to_datetime(df_electricity[\"data\"], format=\"%d/%m/%Y\")\n",
    "df_climatic[\"data\"] = pd.to_datetime(df_climatic[\"data\"], format=\"%d/%m/%Y\")\n",
    "\n",
    "df_water.set_index(\"data\", inplace=True)\n",
    "df_electricity.set_index(\"data\", inplace=True)\n",
    "df_climatic.set_index(\"data\", inplace=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73429363fb53c4ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pré-Processamento\n",
    "## Dados climáticos faltantes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "559730eb71e02daa"
  },
  {
   "cell_type": "code",
   "source": [
    "for index, row in df_climatic[df_climatic.isnull()].to_pandas().iterrows():\n",
    "    df_mes = df_climatic[df_climatic[\"mes\"] == df_climatic.at[index, \"mes\"]]\n",
    "    for col in row.index:\n",
    "        if pandas.isnull(df_climatic.at[index, col]):\n",
    "            df_mes.at[index, col] = df_mes[col].sum() / df_mes[col][df_mes[col].isnull() == False].count()\n",
    "            df_climatic.at[index, col] = df_mes.at[index, col]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20ae521d263691c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Obtenção dos LAGS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8097a93df49fe1a8"
  },
  {
   "cell_type": "code",
   "source": [
    "for lag_col in [\"consumo\"]:\n",
    "    for i in range(1, 12 + 1):\n",
    "        lag_eletricity = df_electricity[lag_col].shift(i)\n",
    "        df_electricity[f'{lag_col}_LAG_' + '{:02d}'.format(i)] = lag_eletricity\n",
    "\n",
    "        lag_water = df_water[lag_col].shift(i)\n",
    "        df_water[f'{lag_col}_LAG_' + '{:02d}'.format(i)] = lag_water"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59c87d57d33178",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## União dos dados climáticos aos dados de consumo"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf455533d3b84e8b"
  },
  {
   "cell_type": "code",
   "source": [
    "df_water = pd.merge(left=df_water, right=df_climatic, on=[\"data\", \"mes\", \"ano\"], how=\"left\")\n",
    "df_water = df_water.drop(\"leitura\", axis=1)\n",
    "\n",
    "df_electricity = pd.merge(left=df_electricity, right=df_climatic, on=[\"data\", \"mes\", \"ano\"], how=\"left\")\n",
    "df_electricity = df_electricity.drop(\"leitura\", axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "245bb664be419ac8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Criação das variáveis Dummy (mês e ano)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c520eeb0184fc5b"
  },
  {
   "cell_type": "code",
   "source": [
    "df_meses = pd.get_dummies(df_electricity[\"mes\"].astype(int), prefix=\"\", prefix_sep=\"\", dtype=int).rename(\n",
    "    columns={\"1\": \"mes_JAN\", \"2\": \"mes_FEV\", \"3\": \"mes_MAR\", \"4\": \"mes_ABR\", \"5\": \"mes_MAI\", \"6\": \"mes_JUN\",\n",
    "             \"7\": \"mes_JUL\", \"8\": \"mes_AGO\", \"9\": \"mes_SET\", \"10\": \"mes_OUT\", \"11\": \"mes_NOV\", \"12\": \"mes_DEZ\"}\n",
    ")\n",
    "df_anos = pd.get_dummies(df_electricity[\"ano\"].astype(int), prefix=\"\", prefix_sep=\"\", dtype=int).rename(\n",
    "    columns={\"2017\": \"ano_2017\", \"2018\": \"ano_2018\", \"2019\": \"ano_2019\", \"2020\": \"ano_2020\", \"2021\": \"ano_2021\",\n",
    "             \"2022\": \"ano_2022\", \"2023\": \"ano_2023\", \"2024\": \"ano_2024\"}\n",
    ")\n",
    "df_electricity = pd.concat([df_electricity, df_meses, df_anos], axis=1)\n",
    "df_electricity = df_electricity.drop([\"mes\", \"ano\"], axis=1)\n",
    "df_electricity = df_electricity.astype(\"float32\").dropna()\n",
    "\n",
    "df_meses = pd.get_dummies(df_water[\"mes\"].astype(int), prefix=\"\", prefix_sep=\"\", dtype=int).rename(\n",
    "    columns={\"1\": \"mes_JAN\", \"2\": \"mes_FEV\", \"3\": \"mes_MAR\", \"4\": \"mes_ABR\", \"5\": \"mes_MAI\", \"6\": \"mes_JUN\",\n",
    "             \"7\": \"mes_JUL\", \"8\": \"mes_AGO\", \"9\": \"mes_SET\", \"10\": \"mes_OUT\", \"11\": \"mes_NOV\", \"12\": \"mes_DEZ\"}\n",
    ")\n",
    "df_anos = pd.get_dummies(df_water[\"ano\"].astype(int), prefix=\"\", prefix_sep=\"\", dtype=int).rename(\n",
    "    columns={\"2017\": \"ano_2017\", \"2018\": \"ano_2018\", \"2019\": \"ano_2019\", \"2020\": \"ano_2020\", \"2021\": \"ano_2021\",\n",
    "             \"2022\": \"ano_2022\", \"2023\": \"ano_2023\", \"2024\": \"ano_2024\"}\n",
    ")\n",
    "df_water = pd.concat([df_water, df_meses, df_anos], axis=1)\n",
    "df_water = df_water.drop([\"mes\", \"ano\"], axis=1)\n",
    "df_water = df_water.astype(\"float32\").dropna()\n",
    "\n",
    "df_show = df_electricity.to_pandas()\n",
    "df_show"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3350975c606ba2f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "420d7768ec87dff0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Análise de Correlações\n",
    "## Eletricidade\n",
    "### Correlação com os LAGS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6fbbaaa4d4bf3e0"
  },
  {
   "cell_type": "code",
   "source": [
    "corr_matrix = df_electricity[df_electricity.to_pandas().filter(like=\"consumo\").columns].dropna().to_pandas().corr(\n",
    "    numeric_only=True)\n",
    "sns.heatmap(corr_matrix,\n",
    "            cmap=\"coolwarm\",\n",
    "            center=0,\n",
    "            annot=True,\n",
    "            fmt='.0g')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "203cab94b7b5dc4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Correlação com as variáveis climáticas"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da6d0ec86da92621"
  },
  {
   "cell_type": "code",
   "source": [
    "corr_matrix = df_electricity.drop(df_electricity.to_pandas().filter(like=\"_LAG_\").columns,\n",
    "                                  axis=1).drop(df_electricity.to_pandas().filter(like=\"mes_\").columns,\n",
    "                                               axis=1).drop(df_electricity.to_pandas().filter(like=\"ano_\").columns,\n",
    "                                                            axis=1).dropna().to_pandas().corr(numeric_only=True)\n",
    "sns.heatmap(corr_matrix,\n",
    "            cmap=\"coolwarm\",\n",
    "            center=0,\n",
    "            annot=True,\n",
    "            fmt='.1g')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a25983797d302706",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Água\n",
    "### Correlação com os LAGS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d9483fd42957a34"
  },
  {
   "cell_type": "code",
   "source": [
    "corr_matrix = df_water[df_water.to_pandas().filter(like=\"consumo\").columns].dropna().to_pandas().corr(numeric_only=True)\n",
    "sns.heatmap(corr_matrix,\n",
    "            cmap=\"coolwarm\",\n",
    "            center=0,\n",
    "            annot=True,\n",
    "            fmt='.0g')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2527f240a158ae44",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Correlação com as variáveis climáticas"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71dc952b4e1ab031"
  },
  {
   "cell_type": "code",
   "source": [
    "corr_matrix = df_water.drop(df_water.to_pandas().filter(like=\"_LAG_\").columns,\n",
    "                            axis=1).drop(df_water.to_pandas().filter(like=\"mes_\").columns,\n",
    "                                         axis=1).drop(df_water.to_pandas().filter(like=\"ano_\").columns,\n",
    "                                                      axis=1).dropna().to_pandas().corr(numeric_only=True)\n",
    "sns.heatmap(corr_matrix,\n",
    "            cmap=\"coolwarm\",\n",
    "            center=0,\n",
    "            annot=True,\n",
    "            fmt='.1g')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50dd3403096d927d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correlação entre o Consumo de Eletricidade e de Água\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8bd7ba5135da593"
  },
  {
   "cell_type": "code",
   "source": [
    "corr_matrix = pd.merge(left=df_electricity[\"consumo\"], right=df_water[\"consumo\"],\n",
    "                       on=[\"data\"], how=\"inner\",\n",
    "                       suffixes=[' electricity', ' water']).dropna().to_pandas().corr(numeric_only=True)\n",
    "sns.heatmap(corr_matrix,\n",
    "            cmap=\"coolwarm\",\n",
    "            center=0,\n",
    "            annot=True,\n",
    "            fmt='.1g')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc8cc19647b81a53",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Análise dos SHAP Values\n",
    "## Eletricidade\n",
    "### Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b63848b390147d73"
  },
  {
   "cell_type": "code",
   "source": [
    "df_electricity_copy = df_electricity.dropna().copy().to_pandas()\n",
    "\n",
    "x_electricity = df_electricity_copy.drop(\"consumo\", axis=1)\n",
    "y_electricity = df_electricity_copy[\"consumo\"]\n",
    "model_rf = RandomForestRegressor()\n",
    "shap.initjs()\n",
    "\n",
    "model_rf.fit(x_electricity, y_electricity)\n",
    "\n",
    "explainer_rf = shap.Explainer(model_rf)\n",
    "shap_rf = explainer_rf(x_electricity)\n",
    "\n",
    "shap.plots.waterfall(shap_rf[0], max_display=10)\n",
    "shap.plots.force(shap_rf[0])\n",
    "shap.plots.bar(shap_rf)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3dc260de37d498c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### XGBoost"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "314ed5331c39c10"
  },
  {
   "cell_type": "code",
   "source": [
    "df_electricity_copy = df_electricity.dropna().copy().to_pandas()\n",
    "\n",
    "x_electricity = df_electricity_copy.drop(\"consumo\", axis=1)\n",
    "y_electricity = df_electricity_copy[\"consumo\"]\n",
    "\n",
    "model_xgb = XGBRegressor(objective='reg:squarederror')\n",
    "shap.initjs()\n",
    "\n",
    "model_xgb.fit(x_electricity, y_electricity)\n",
    "\n",
    "explainer_xgb = shap.Explainer(model_xgb)\n",
    "shap_xgb = explainer_xgb(x_electricity)\n",
    "\n",
    "shap.plots.waterfall(shap_xgb[0], max_display=10)\n",
    "shap.plots.force(shap_xgb[0])\n",
    "shap.plots.bar(shap_xgb)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25f04550785acb2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Água\n",
    "### Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4d8dad58c4f3a0a"
  },
  {
   "cell_type": "code",
   "source": [
    "df_water_copy = df_water.dropna().copy().to_pandas()\n",
    "\n",
    "x_water = df_water_copy.drop(\"consumo\", axis=1)\n",
    "y_water = df_water_copy[\"consumo\"]\n",
    "model_rf = RandomForestRegressor()\n",
    "shap.initjs()\n",
    "\n",
    "model_rf.fit(x_water, y_water)\n",
    "\n",
    "explainer_rf = shap.Explainer(model_rf)\n",
    "shap_rf = explainer_rf(x_water)\n",
    "\n",
    "shap.plots.waterfall(shap_rf[0], max_display=10)\n",
    "shap.plots.force(shap_rf[0])\n",
    "shap.plots.bar(shap_rf)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3a887cd8e14ee58",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### XGBoost"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "355813e190d32d81"
  },
  {
   "cell_type": "code",
   "source": [
    "df_water_copy = df_water.dropna().copy().to_pandas()\n",
    "\n",
    "x_water = df_water_copy.drop(\"consumo\", axis=1)\n",
    "y_water = df_water_copy[\"consumo\"]\n",
    "\n",
    "model_xgb = XGBRegressor(objective='reg:squarederror')\n",
    "shap.initjs()\n",
    "\n",
    "model_xgb.fit(x_water, y_water)\n",
    "\n",
    "explainer_xgb = shap.Explainer(model_xgb)\n",
    "shap_xgb = explainer_xgb(x_water)\n",
    "\n",
    "shap.plots.waterfall(shap_xgb[0], max_display=10)\n",
    "shap.plots.force(shap_xgb[0])\n",
    "shap.plots.bar(shap_xgb)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cb289a4dcf1c603",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Configuração dos Otimizadores\n",
    "## Algoritmo Genético\n",
    "### Indivíduos"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a20cb439079a737"
  },
  {
   "cell_type": "code",
   "source": [
    "class IndXGB:\n",
    "    def __init__(self):\n",
    "        self.fitness = None\n",
    "        self.estimators = 0\n",
    "        self.max_depth = 0\n",
    "        self.booster = None\n",
    "\n",
    "    def create_random(self):\n",
    "        self.rand_estimators()\n",
    "        self.rand_depth()\n",
    "        self.rand_booster()\n",
    "        return self\n",
    "\n",
    "    def rand_estimators(self):\n",
    "        self.estimators = random.randint(1, 300)\n",
    "\n",
    "    def rand_depth(self):\n",
    "        self.max_depth = random.randint(1, 300)\n",
    "\n",
    "    def rand_booster(self):\n",
    "        self.booster = random.choice([\"gbtree\", \"gblinear\", \"dart\"])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66c830f88912d062",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Operações"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a77d8f401e9367b"
  },
  {
   "cell_type": "code",
   "source": [
    "class GAXGB:\n",
    "    def __init__(self, dataset, n_individuals, n_generations, mutation_rate, seed=SEED):\n",
    "        reset_seed(seed)\n",
    "        self.dataset = dataset\n",
    "        self.n_individuals = n_individuals\n",
    "        self.n_generations = n_generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.population = []\n",
    "        self.init_pop()\n",
    "        self.init_gen()\n",
    "\n",
    "    def init_pop(self):\n",
    "        for _ in range(self.n_individuals):\n",
    "            ind = IndXGB().create_random()\n",
    "            ind = self.get_fitness(ind)\n",
    "            self.population.append(ind)\n",
    "            self.population = sorted(self.population, key=lambda a: a.fitness)\n",
    "\n",
    "    def init_gen(self):\n",
    "        for _ in range(self.n_generations):\n",
    "            ind_a = self.population[0]\n",
    "            ind_b = random.choice(self.population)\n",
    "            ind_c = self.crossover(ind_a, ind_b)\n",
    "            if random.uniform(0, 1) < self.mutation_rate:\n",
    "                ind_c = self.mutation(ind_c)\n",
    "            ind_c = self.get_fitness(ind_c)\n",
    "            self.population.append(ind_c)\n",
    "            self.population = sorted(self.population, key=lambda a: a.fitness)\n",
    "\n",
    "    def mutation(self, ind):\n",
    "        random.choice([\n",
    "            ind.rand_estimators(),\n",
    "            ind.rand_depth(),\n",
    "            ind.rand_booster()\n",
    "        ])\n",
    "        return ind\n",
    "\n",
    "    def crossover(self, ind_a, ind_b):\n",
    "        ind = IndXGB()\n",
    "        ind.estimators = random.choice([ind_a.estimators, ind_b.estimators])\n",
    "        ind.max_depth = random.choice([ind_a.max_depth, ind_b.max_depth])\n",
    "        ind.booster = random.choice([ind_a.booster, ind_b.booster])\n",
    "        return ind\n",
    "\n",
    "    def get_fitness(self, individual):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(self.dataset.drop(\"consumo\", axis=1),\n",
    "                                                            self.dataset[\"consumo\"],\n",
    "                                                            test_size=1, shuffle=False)\n",
    "\n",
    "        model = XGBRegressor(n_estimators=individual.estimators, max_depth=individual.max_depth,\n",
    "                             booster=individual.booster,\n",
    "                             device=\"cuda\",\n",
    "                             verbose=False)\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        individual.fitness = int(mean_squared_error(y_test, model.predict(x_test)).get())\n",
    "        return individual\n",
    "\n",
    "    def population_dataframe(self):\n",
    "        df = cudf.DataFrame()\n",
    "        for ind in self.population:\n",
    "            df = cudf.concat([df, cudf.DataFrame({\n",
    "                \"N_estimators\": ind.estimators,\n",
    "                \"Max_depth\": ind.max_depth,\n",
    "                \"Booster\": ind.booster,\n",
    "                \"Fitness\": ind.fitness\n",
    "            })])\n",
    "        return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T18:39:07.802748Z",
     "start_time": "2024-06-15T18:39:07.772497Z"
    }
   },
   "id": "75eecff7358788e",
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Enxame de Partículas\n",
    "### Particulas"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "921a2196f8f7a5a6"
  },
  {
   "cell_type": "code",
   "source": [
    "class PartXGB:\n",
    "    def __init_(self):\n",
    "        self.fitness = None\n",
    "        self.estimators = 0\n",
    "        self.max_depth = 0\n",
    "        self.booster = None\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4c6224298ba6589",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Operações",
   "id": "d8c75e15d55b3708"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T19:29:42.659859Z",
     "start_time": "2024-06-15T19:29:42.622985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PSOXGB:\n",
    "    def __init__(self, dataset, n_particles, n_iters, seed=SEED):\n",
    "        reset_seed(seed)\n",
    "        self.seed = seed\n",
    "        self.dataset = dataset\n",
    "        self.n_particles = n_particles\n",
    "        self.n_iters = n_iters\n",
    "        self.particles = []\n",
    "        self.BOOSTERS = [\"gbtree\", \"gblinear\", \"dart\"]\n",
    "        self.run()\n",
    "\n",
    "    def run(self):\n",
    "        lower_bound = [1, 1, 0]\n",
    "        uppper_bound = [300, 300, 2]\n",
    "        bounds = (lower_bound, uppper_bound)\n",
    "\n",
    "        options = {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
    "        optimizer = GlobalBestPSO(n_particles=self.n_particles,\n",
    "                                  dimensions=3,\n",
    "                                  options=options,\n",
    "                                  bounds=bounds)\n",
    "\n",
    "        optimizer.optimize(self.get_fitness, iters=self.n_iters)\n",
    "        self.particles = sorted(self.particles, key=lambda a: a.fitness)\n",
    "\n",
    "    def get_fitness(self, particles):\n",
    "        particles = np.round(particles)\n",
    "        fitness_list = []\n",
    "        for j in range(self.n_particles):\n",
    "            fitness_list.append(self.objective_function(particles[j]))\n",
    "        return fitness_list\n",
    "\n",
    "    def objective_function(self, particle_arr):\n",
    "        reset_seed(self.seed)\n",
    "        particle = PartXGB()\n",
    "        particle.estimators = int(particle_arr[0])\n",
    "        particle.max_depth = int(particle_arr[1])\n",
    "        particle.booster = self.BOOSTERS[int(particle_arr[2])]\n",
    "        \n",
    "        if particle.booster == \"gblinear\":\n",
    "            updater = \"coord_descent\"\n",
    "        else:\n",
    "            updater = None\n",
    "        x_train, x_test, y_train, y_test = train_test_split(self.dataset.drop(\"consumo\", axis=1),\n",
    "                                                            self.dataset[\"consumo\"],\n",
    "                                                            test_size=1, shuffle=False,\n",
    "                                                            random_state=self.seed)\n",
    "        model = XGBRegressor(device=\"cuda\", random_state=self.seed,\n",
    "                             n_estimators=particle.estimators,\n",
    "                             max_depth=particle.max_depth, updater=updater,\n",
    "                             booster=particle.booster, verbosity=0)\n",
    "        model.fit(x_train, y_train)\n",
    "        particle.fitness = int(mean_squared_error(y_test, model.predict(x_test)).get())\n",
    "\n",
    "        self.particles.append(particle)\n",
    "        return particle.fitness\n",
    "\n",
    "    def particles_dataframe(self):\n",
    "        df = cudf.DataFrame()\n",
    "        for part in self.particles:\n",
    "            df = cudf.concat([df, cudf.DataFrame({\n",
    "                \"N_estimators\": part.estimators,\n",
    "                \"Max_depth\": part.max_depth,\n",
    "                \"Booster\": part.booster,\n",
    "                \"Fitness\": part.fitness\n",
    "            })])\n",
    "        return df\n",
    "\n"
   ],
   "id": "e77384b77f35ffe4",
   "outputs": [],
   "execution_count": 82
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Aplicação dos Otimizadores\n",
    "## Random Forest\n",
    "### Eletricidade"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fff4de69f44d41d"
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "collapsed": false
   },
   "id": "236caf6730ed692a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Água"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc937ec3c78bc4c1"
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e5ec6ca3b4604bee",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost\n",
    "### Eletricidade"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e74855edc797a8e6"
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "pso_xgb = PSOXGB(df_electricity, 2, 2, 2000)\n",
    "pso_xgb.particles_dataframe()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-15T19:30:32.597087Z",
     "start_time": "2024-06-15T19:30:15.824180Z"
    }
   },
   "id": "fc270813a7c3a24c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-15 16:30:15,858 - pyswarms.single.global_best - INFO - Optimize for 2 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best:   0%|          |0/2/home/eduardoalba0/.conda/envs/rapids-24.06/lib/python3.11/site-packages/xgboost/data.py:849: FutureWarning: Index.format is deprecated and will be removed in a future version. Convert using index.astype(str) or index.map(formatter) instead.\n",
      "  feature_names = data.columns.format()\n",
      "/home/eduardoalba0/.conda/envs/rapids-24.06/lib/python3.11/site-packages/xgboost/data.py:849: FutureWarning: Index.format is deprecated and will be removed in a future version. Convert using index.astype(str) or index.map(formatter) instead.\n",
      "  feature_names = data.columns.format()\n",
      "/home/eduardoalba0/.conda/envs/rapids-24.06/lib/python3.11/site-packages/xgboost/data.py:849: FutureWarning: Index.format is deprecated and will be removed in a future version. Convert using index.astype(str) or index.map(formatter) instead.\n",
      "  feature_names = data.columns.format()\n",
      "/home/eduardoalba0/.conda/envs/rapids-24.06/lib/python3.11/site-packages/xgboost/data.py:849: FutureWarning: Index.format is deprecated and will be removed in a future version. Convert using index.astype(str) or index.map(formatter) instead.\n",
      "  feature_names = data.columns.format()\n",
      "pyswarms.single.global_best:  50%|█████     |1/2, best_cost=3.59e+5/home/eduardoalba0/.conda/envs/rapids-24.06/lib/python3.11/site-packages/xgboost/data.py:849: FutureWarning: Index.format is deprecated and will be removed in a future version. Convert using index.astype(str) or index.map(formatter) instead.\n",
      "  feature_names = data.columns.format()\n",
      "/home/eduardoalba0/.conda/envs/rapids-24.06/lib/python3.11/site-packages/xgboost/data.py:849: FutureWarning: Index.format is deprecated and will be removed in a future version. Convert using index.astype(str) or index.map(formatter) instead.\n",
      "  feature_names = data.columns.format()\n",
      "/home/eduardoalba0/.conda/envs/rapids-24.06/lib/python3.11/site-packages/xgboost/data.py:849: FutureWarning: Index.format is deprecated and will be removed in a future version. Convert using index.astype(str) or index.map(formatter) instead.\n",
      "  feature_names = data.columns.format()\n",
      "/home/eduardoalba0/.conda/envs/rapids-24.06/lib/python3.11/site-packages/xgboost/data.py:849: FutureWarning: Index.format is deprecated and will be removed in a future version. Convert using index.astype(str) or index.map(formatter) instead.\n",
      "  feature_names = data.columns.format()\n",
      "pyswarms.single.global_best: 100%|██████████|2/2, best_cost=4010.0 \n",
      "2024-06-15 16:30:32,456 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 4010.0, best pos: [259.83607151  68.46491371   0.71714416]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   N_estimators  Max_depth   Booster   Fitness\n",
       "0           260         68  gblinear      4010\n",
       "0            99        209  gblinear    358967\n",
       "0            99        209  gblinear    358967\n",
       "0           268         61    gbtree  56027492"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_estimators</th>\n",
       "      <th>Max_depth</th>\n",
       "      <th>Booster</th>\n",
       "      <th>Fitness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>260</td>\n",
       "      <td>68</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>4010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>209</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>358967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>209</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>358967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268</td>\n",
       "      <td>61</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>56027492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 84
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Água"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66c5108781953126"
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "collapsed": false
   },
   "id": "4600cff3602b1450",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVR\n",
    "### Eletricidade"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27bdb2e123c383c1"
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "collapsed": false
   },
   "id": "84d7a6c888949595",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Água"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b22084680bbdfd0"
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a5ccd835cf107b86",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LSTM\n",
    "### Eletricidade"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e8ddf2c403efbc8"
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "129ca77e5926db8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Água"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51d4ba73afbb49ed"
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3a87f082bb4abbd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost\n",
    "### Eletricidade"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "343de022a985230"
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e3e7417570c475a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Água"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f74c2bd2cb478bf3"
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b246dc3cfe1cff4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Previsões\n",
    "## Eletricidade\n",
    "### 3 Passos à frente"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29405b274310a71b"
  },
  {
   "cell_type": "code",
   "source": [
    "# reset_seed()\n",
    "# x_electricity = df_electricity.drop(\"consumo\", axis=1)\n",
    "# y_electricity = df_electricity[\"consumo\"]\n",
    "# \n",
    "# xgb_electricity = XGBRegressor()\n",
    "# rf_electricity = CuRF(n_streams=1, n_bins=x_electricity.shape[1])\n",
    "# svr_electricity = SVR()\n",
    "# lstm_electricity = Sequential([\n",
    "#     Input((x_electricity.shape[1], 1), batch_size=x_electricity.shape[1]),\n",
    "#     LSTM(30, activation='relu', seed=SEED),\n",
    "#     Dense(1),\n",
    "# ])\n",
    "# lstm_electricity.compile(loss='mse', metrics=['mean_absolute_error'])\n",
    "# \n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_electricity, y_electricity, test_size=3, shuffle=False)\n",
    "# \n",
    "# cvs_electricity = pd.DataFrame()\n",
    "# for i_train, i_test in TimeSeriesSplit(n_splits=12, test_size=1).split(x_train, y_train):\n",
    "#     kx_train, kx_test = x_train.iloc[i_train].to_numpy(), x_train.iloc[i_test].to_numpy()\n",
    "#     ky_train, ky_test = y_train.iloc[i_train].to_numpy(), y_train.iloc[i_test].to_numpy()\n",
    "# \n",
    "#     xgb_electricity.fit(kx_train, ky_train)\n",
    "#     rf_electricity.fit(kx_train, ky_train)\n",
    "#     svr_electricity.fit(kx_train, ky_train)\n",
    "#     lstm_electricity.fit(kx_train, ky_train, shuffle=False, verbose=False, epochs=1, batch_size=x_electricity.shape[1])\n",
    "#     cvs_electricity = pd.concat([cvs_electricity, pd.DataFrame({\n",
    "#         \"XGB\": mean_absolute_percentage_error(xgb_electricity.predict(kx_test), ky_test),\n",
    "#         \"RF\": mean_absolute_percentage_error(rf_electricity.predict(kx_test), ky_test),\n",
    "#         \"SVR\": mean_absolute_percentage_error(svr_electricity.predict(kx_test), ky_test),\n",
    "#         \"LSTM\": mean_absolute_percentage_error(lstm_electricity.predict(kx_test), ky_test)\n",
    "#     })])\n",
    "# \n",
    "# pred_xgb_electricity = []\n",
    "# for i_test in range(len(x_test)):\n",
    "#     sx_test = x_test.iloc[[i_test]]\n",
    "# \n",
    "#     for climatic_column in df_climatic.drop([\"ano\", \"mes\"], axis=1).columns:\n",
    "#         sx_test.at[sx_test.index, climatic_column] = \\\n",
    "#             x_electricity.at[(sx_test.index - pd.DateOffset(years=1)), climatic_column].to_numpy()[0][0]\n",
    "#     for lag in range(i_test + 1):\n",
    "#         if lag == 0:\n",
    "#             continue\n",
    "#         sx_test['consumo_LAG_' + \"{:02d}\".format(lag)] = pred_xgb_electricity[-lag]\n",
    "# \n",
    "#     pred_xgb_electricity.append(xgb_electricity.predict(sx_test.to_numpy())[0])\n",
    "# \n",
    "# pred_rf_electricity = []\n",
    "# for i_test in range(len(x_test)):\n",
    "#     sx_test = x_test.iloc[[i_test]]\n",
    "# \n",
    "#     for climatic_column in df_climatic.drop([\"ano\", \"mes\"], axis=1).columns:\n",
    "#         sx_test.at[sx_test.index, climatic_column] = \\\n",
    "#             x_electricity.at[(sx_test.index - pd.DateOffset(years=1)), climatic_column].to_numpy()[0][0]\n",
    "#     for lag in range(i_test + 1):\n",
    "#         if lag == 0:\n",
    "#             continue\n",
    "#         sx_test['consumo_LAG_' + \"{:02d}\".format(lag)] = pred_rf_electricity[-lag]\n",
    "# \n",
    "#     pred_rf_electricity.append(rf_electricity.predict(sx_test.to_numpy())[0])\n",
    "# \n",
    "# pred_svr_electricity = []\n",
    "# for i_test in range(len(x_test)):\n",
    "#     sx_test = x_test.iloc[[i_test]]\n",
    "# \n",
    "#     for climatic_column in df_climatic.drop([\"ano\", \"mes\"], axis=1).columns:\n",
    "#         sx_test.at[sx_test.index, climatic_column] = \\\n",
    "#             x_electricity.at[(sx_test.index - pd.DateOffset(years=1)), climatic_column].to_numpy()[0][0]\n",
    "#     for lag in range(i_test + 1):\n",
    "#         if lag == 0:\n",
    "#             continue\n",
    "#         sx_test['consumo_LAG_' + \"{:02d}\".format(lag)] = pred_svr_electricity[-lag]\n",
    "# \n",
    "#     pred_svr_electricity.append(svr_electricity.predict(sx_test.to_numpy())[0])\n",
    "# \n",
    "# pred_lstm_electricity = []\n",
    "# for i_test in range(len(x_test)):\n",
    "#     sx_test = x_test.iloc[[i_test]]\n",
    "# \n",
    "#     for climatic_column in df_climatic.drop([\"ano\", \"mes\"], axis=1).columns:\n",
    "#         sx_test.at[sx_test.index, climatic_column] = \\\n",
    "#             x_electricity.at[(sx_test.index - pd.DateOffset(years=1)), climatic_column].to_numpy()[0][0]\n",
    "#     for lag in range(i_test + 1):\n",
    "#         if lag == 0:\n",
    "#             continue\n",
    "#         sx_test['consumo_LAG_' + \"{:02d}\".format(lag)] = pred_lstm_electricity[-lag]\n",
    "# \n",
    "#     pred_lstm_electricity.append(lstm_electricity.predict(sx_test.to_numpy())[0])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "affa8389121b3b03",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6 Passos à frente"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16178f65debc9ff4"
  },
  {
   "cell_type": "code",
   "source": [
    "# reset_seed()\n",
    "# x_electricity = df_electricity.drop(\"consumo\", axis=1)\n",
    "# y_electricity = df_electricity[\"consumo\"]\n",
    "# \n",
    "# xgb_electricity = XGBRegressor()\n",
    "# rf_electricity = CuRF(n_streams=1, n_bins=x_electricity.shape[1])\n",
    "# svr_electricity = SVR()\n",
    "# lstm_electricity = Sequential([\n",
    "#     Input((x_electricity.shape[1], 1), batch_size=x_electricity.shape[1]),\n",
    "#     LSTM(30, activation='relu', seed=SEED),\n",
    "#     Dense(1),\n",
    "# ])\n",
    "# lstm_electricity.compile(loss='mse', metrics=['mean_absolute_error'])\n",
    "# \n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_electricity, y_electricity, test_size=6, shuffle=False)\n",
    "# \n",
    "# cvs_electricity = pd.DataFrame()\n",
    "# for i_train, i_test in TimeSeriesSplit(n_splits=12, test_size=1).split(x_train, y_train):\n",
    "#     kx_train, kx_test = x_train.iloc[i_train].to_numpy(), x_train.iloc[i_test].to_numpy()\n",
    "#     ky_train, ky_test = y_train.iloc[i_train].to_numpy(), y_train.iloc[i_test].to_numpy()\n",
    "# \n",
    "#     xgb_electricity.fit(kx_train, ky_train)\n",
    "#     rf_electricity.fit(kx_train, ky_train)\n",
    "#     svr_electricity.fit(kx_train, ky_train)\n",
    "#     lstm_electricity.fit(kx_train, ky_train, shuffle=False, verbose=False, epochs=1, batch_size=x_electricity.shape[1])\n",
    "#     cvs_electricity = pd.concat([cvs_electricity, pd.DataFrame({\n",
    "#         \"XGB\": mean_absolute_percentage_error(xgb_electricity.predict(kx_test), ky_test),\n",
    "#         \"RF\": mean_absolute_percentage_error(rf_electricity.predict(kx_test), ky_test),\n",
    "#         \"SVR\": mean_absolute_percentage_error(svr_electricity.predict(kx_test), ky_test),\n",
    "#         \"LSTM\": mean_absolute_percentage_error(lstm_electricity.predict(kx_test), ky_test)\n",
    "#     })])\n",
    "# \n",
    "# pred_xgb_electricity = []\n",
    "# for i_test in range(len(x_test)):\n",
    "#     sx_test = x_test.iloc[[i_test]]\n",
    "# \n",
    "#     for climatic_column in df_climatic.drop([\"ano\", \"mes\"], axis=1).columns:\n",
    "#         sx_test.at[sx_test.index, climatic_column] = \\\n",
    "#             x_electricity.at[(sx_test.index - pd.DateOffset(years=1)), climatic_column].to_numpy()[0][0]\n",
    "#     for lag in range(i_test + 1):\n",
    "#         if lag == 0:\n",
    "#             continue\n",
    "#         sx_test['consumo_LAG_' + \"{:02d}\".format(lag)] = pred_xgb_electricity[-lag]\n",
    "# \n",
    "#     pred_xgb_electricity.append(xgb_electricity.predict(sx_test.to_numpy())[0])\n",
    "# \n",
    "# pred_rf_electricity = []\n",
    "# for i_test in range(len(x_test)):\n",
    "#     sx_test = x_test.iloc[[i_test]]\n",
    "# \n",
    "#     for climatic_column in df_climatic.drop([\"ano\", \"mes\"], axis=1).columns:\n",
    "#         sx_test.at[sx_test.index, climatic_column] = \\\n",
    "#             x_electricity.at[(sx_test.index - pd.DateOffset(years=1)), climatic_column].to_numpy()[0][0]\n",
    "#     for lag in range(i_test + 1):\n",
    "#         if lag == 0:\n",
    "#             continue\n",
    "#         sx_test['consumo_LAG_' + \"{:02d}\".format(lag)] = pred_rf_electricity[-lag]\n",
    "# \n",
    "#     pred_rf_electricity.append(rf_electricity.predict(sx_test.to_numpy())[0])\n",
    "# \n",
    "# pred_svr_electricity = []\n",
    "# for i_test in range(len(x_test)):\n",
    "#     sx_test = x_test.iloc[[i_test]]\n",
    "# \n",
    "#     for climatic_column in df_climatic.drop([\"ano\", \"mes\"], axis=1).columns:\n",
    "#         sx_test.at[sx_test.index, climatic_column] = \\\n",
    "#             x_electricity.at[(sx_test.index - pd.DateOffset(years=1)), climatic_column].to_numpy()[0][0]\n",
    "#     for lag in range(i_test + 1):\n",
    "#         if lag == 0:\n",
    "#             continue\n",
    "#         sx_test['consumo_LAG_' + \"{:02d}\".format(lag)] = pred_svr_electricity[-lag]\n",
    "# \n",
    "#     pred_svr_electricity.append(svr_electricity.predict(sx_test.to_numpy())[0])\n",
    "# \n",
    "# pred_lstm_electricity = []\n",
    "# for i_test in range(len(x_test)):\n",
    "#     sx_test = x_test.iloc[[i_test]]\n",
    "# \n",
    "#     for climatic_column in df_climatic.drop([\"ano\", \"mes\"], axis=1).columns:\n",
    "#         sx_test.at[sx_test.index, climatic_column] = \\\n",
    "#             x_electricity.at[(sx_test.index - pd.DateOffset(years=1)), climatic_column].to_numpy()[0][0]\n",
    "#     for lag in range(i_test + 1):\n",
    "#         if lag == 0:\n",
    "#             continue\n",
    "#         sx_test['consumo_LAG_' + \"{:02d}\".format(lag)] = pred_lstm_electricity[-lag]\n",
    "# \n",
    "#     pred_lstm_electricity.append(lstm_electricity.predict(sx_test.to_numpy())[0])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6659cf7ebd8217fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### 12 Passos à frente",
   "metadata": {
    "collapsed": false
   },
   "id": "4f58661c14d4c9ed"
  },
  {
   "cell_type": "code",
   "source": [
    "# reset_seed()\n",
    "# x_electricity = df_electricity.drop(\"consumo\", axis=1)\n",
    "# y_electricity = df_electricity[\"consumo\"]\n",
    "# \n",
    "# xgb_electricity = XGBRegressor()\n",
    "# rf_electricity = CuRF(n_streams=1, n_bins=x_electricity.shape[1])\n",
    "# svr_electricity = SVR()\n",
    "# lstm_electricity = Sequential([\n",
    "#     Input((x_electricity.shape[1], 1), batch_size=x_electricity.shape[1]),\n",
    "#     LSTM(30, activation='relu', seed=SEED),\n",
    "#     Dense(1),\n",
    "# ])\n",
    "# lstm_electricity.compile(loss='mse', metrics=['mean_absolute_error'])\n",
    "# \n",
    "# x_train, x_test, y_train, y_test = train_test_split(x_electricity, y_electricity, test_size=12, shuffle=False)\n",
    "# \n",
    "# cvs_electricity = pd.DataFrame()\n",
    "# for i_train, i_test in TimeSeriesSplit(n_splits=12, test_size=1).split(x_train, y_train):\n",
    "#     kx_train, kx_test = x_train.iloc[i_train].to_numpy(), x_train.iloc[i_test].to_numpy()\n",
    "#     ky_train, ky_test = y_train.iloc[i_train].to_numpy(), y_train.iloc[i_test].to_numpy()\n",
    "# \n",
    "#     xgb_electricity.fit(kx_train, ky_train)\n",
    "#     rf_electricity.fit(kx_train, ky_train)\n",
    "#     svr_electricity.fit(kx_train, ky_train)\n",
    "#     lstm_electricity.fit(kx_train, ky_train, shuffle=False, verbose=False, epochs=1, batch_size=x_electricity.shape[1])\n",
    "#     cvs_electricity = pd.concat([cvs_electricity, pd.DataFrame({\n",
    "#         \"XGB\": mean_absolute_percentage_error(xgb_electricity.predict(kx_test), ky_test),\n",
    "#         \"RF\": mean_absolute_percentage_error(rf_electricity.predict(kx_test), ky_test),\n",
    "#         \"SVR\": mean_absolute_percentage_error(svr_electricity.predict(kx_test), ky_test),\n",
    "#         \"LSTM\": mean_absolute_percentage_error(lstm_electricity.predict(kx_test), ky_test)\n",
    "#     })])\n",
    "# \n",
    "# pred_xgb_electricity = []\n",
    "# for i_test in range(len(x_test)):\n",
    "#     sx_test = x_test.iloc[[i_test]]\n",
    "# \n",
    "#     for climatic_column in df_climatic.drop([\"ano\", \"mes\"], axis=1).columns:\n",
    "#         sx_test.at[sx_test.index, climatic_column] = \\\n",
    "#             x_electricity.at[(sx_test.index - pd.DateOffset(years=1)), climatic_column].to_numpy()[0][0]\n",
    "#     for lag in range(i_test + 1):\n",
    "#         if lag == 0:\n",
    "#             continue\n",
    "#         sx_test['consumo_LAG_' + \"{:02d}\".format(lag)] = pred_xgb_electricity[-lag]\n",
    "# \n",
    "#     pred_xgb_electricity.append(xgb_electricity.predict(sx_test.to_numpy())[0])\n",
    "# \n",
    "# pred_rf_electricity = []\n",
    "# for i_test in range(len(x_test)):\n",
    "#     sx_test = x_test.iloc[[i_test]]\n",
    "# \n",
    "#     for climatic_column in df_climatic.drop([\"ano\", \"mes\"], axis=1).columns:\n",
    "#         sx_test.at[sx_test.index, climatic_column] = \\\n",
    "#             x_electricity.at[(sx_test.index - pd.DateOffset(years=1)), climatic_column].to_numpy()[0][0]\n",
    "#     for lag in range(i_test + 1):\n",
    "#         if lag == 0:\n",
    "#             continue\n",
    "#         sx_test['consumo_LAG_' + \"{:02d}\".format(lag)] = pred_rf_electricity[-lag]\n",
    "# \n",
    "#     pred_rf_electricity.append(rf_electricity.predict(sx_test.to_numpy())[0])\n",
    "# \n",
    "# pred_svr_electricity = []\n",
    "# for i_test in range(len(x_test)):\n",
    "#     sx_test = x_test.iloc[[i_test]]\n",
    "# \n",
    "#     for climatic_column in df_climatic.drop([\"ano\", \"mes\"], axis=1).columns:\n",
    "#         sx_test.at[sx_test.index, climatic_column] = \\\n",
    "#             x_electricity.at[(sx_test.index - pd.DateOffset(years=1)), climatic_column].to_numpy()[0][0]\n",
    "#     for lag in range(i_test + 1):\n",
    "#         if lag == 0:\n",
    "#             continue\n",
    "#         sx_test['consumo_LAG_' + \"{:02d}\".format(lag)] = pred_svr_electricity[-lag]\n",
    "# \n",
    "#     pred_svr_electricity.append(svr_electricity.predict(sx_test.to_numpy())[0])\n",
    "# \n",
    "# pred_lstm_electricity = []\n",
    "# for i_test in range(len(x_test)):\n",
    "#     sx_test = x_test.iloc[[i_test]]\n",
    "# \n",
    "#     for climatic_column in df_climatic.drop([\"ano\", \"mes\"], axis=1).columns:\n",
    "#         sx_test.at[sx_test.index, climatic_column] = \\\n",
    "#             x_electricity.at[(sx_test.index - pd.DateOffset(years=1)), climatic_column].to_numpy()[0][0]\n",
    "#     for lag in range(i_test + 1):\n",
    "#         if lag == 0:\n",
    "#             continue\n",
    "#         sx_test['consumo_LAG_' + \"{:02d}\".format(lag)] = pred_lstm_electricity[-lag]\n",
    "# \n",
    "#     pred_lstm_electricity.append(lstm_electricity.predict(sx_test.to_numpy())[0])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53da7b76e64a75a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Água\n",
    "### 3 Passos à frente"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c99bede6775cf6"
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "collapsed": false
   },
   "id": "d8b9b9a43a9d2e99",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6 Passos à frente"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ea5d075f2d6a520"
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "148be2114d695794",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "12 Passos à frente"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "736804d0991388ec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
